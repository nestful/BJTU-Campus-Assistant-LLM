# BJTU Campus Assistant LLM (Qwen2.5-LoRA)

æœ¬é¡¹ç›®åŸºäº [Qwen2.5-1.5B-Instruct](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct) æ¨¡å‹ï¼Œä½¿ç”¨ LoRA (Low-Rank Adaptation) æŠ€æœ¯è¿›è¡Œå¾®è°ƒï¼Œæ—¨åœ¨æ„å»ºä¸€ä¸ªä¸“æ³¨äº BJTUï¼ˆåŒ—äº¬äº¤é€šå¤§å­¦ï¼‰æ ¡å›­äº‹åŠ¡çš„æ™ºèƒ½é—®ç­”åŠ©æ‰‹ã€‚

## ğŸ“Š é¡¹ç›®æ•ˆæœ

é€šè¿‡å¾®è°ƒï¼Œæ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸçš„é—®ç­”èƒ½åŠ›æ˜¾è‘—æå‡ã€‚ä»¥ä¸‹æ˜¯è®­ç»ƒè¿‡ç¨‹åŠè¯„ä¼°æŒ‡æ ‡ï¼š

### è®­ç»ƒä¸æŸå¤±æ›²çº¿

### ![loss_curves](README.assets/loss_curves.png)



## å­¦ä¹ ç‡å˜åŒ–æ›²çº¿ï¼ˆlearningï¼‰

![20251119_193459_learning_rate_curve](README.assets/20251119_193459_learning_rate_curve.png)



### è¯„ä¼°æŒ‡æ ‡å¯¹æ¯” (Base vs LoRA)

å¾®è°ƒå‰ï¼š

![metrics_å¾®è°ƒå‰-1](README.assets/metrics_å¾®è°ƒå‰-1.png)

å¾®è°ƒåï¼š![metrics_å¾®è°ƒå-2](README.assets/metrics_å¾®è°ƒå-2.png)



ä¸»è¦æŒ‡æ ‡æå‡ï¼š

- **å…³é”®è¯å‘½ä¸­ç‡ (KHP):** æ˜¾è‘—æå‡ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°æ•æ‰æ ¡å›­æœ¯è¯­ã€‚
- **å›°æƒ‘åº¦ (PPL):** ä¸‹é™ï¼Œç”Ÿæˆçš„æ–‡æœ¬æ›´åŠ æµç•…è‡ªç„¶ã€‚
- **ROUGE-L:** æå‡ï¼Œå›ç­”å†…å®¹ä¸å‚è€ƒç­”æ¡ˆçš„ç›¸ä¼¼åº¦æ›´é«˜ã€‚

æ¶ˆèç»“æœå›¾ï¼š

![ablation_group1_rank](README.assets/ablation_group1_rank.png)



![ablation_group2_target](README.assets/ablation_group2_target.png)



## ğŸ› ï¸ ç¯å¢ƒå®‰è£…

1. å…‹éš†ä»“åº“ï¼š
```bash
git clone https://github.com/your-username/BJTU-LLM-Finetuning.git
cd BJTU-LLM-Finetuning
```

2. å®‰è£…ä¾èµ–ï¼š
```bash
pip install -r requirements.txt
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æ•°æ®å‡†å¤‡
è¯·ç¡®ä¿æ•°æ®æ”¾ç½®åœ¨ `data/` ç›®å½•ä¸‹ï¼Œæ ¼å¼ä¸º JSON åˆ—è¡¨ï¼š
```json
[
  {
    "instruction": "å¦‚ä½•åŠç†æ ¡å›­å¡ï¼Ÿ",
    "input": "",
    "output": "æ‚¨å¥½ï¼ŒåŠç†æ ¡å›­å¡è¯·å‰å¾€..."
  }
]
```

### 2. æ¨¡å‹å¾®è°ƒ (Training)
è¿è¡Œè®­ç»ƒè„šæœ¬ã€‚è„šæœ¬ä¼šè‡ªåŠ¨åŠ è½½ Qwen2.5-1.5B æ¨¡å‹å¹¶å¼€å§‹ LoRA å¾®è°ƒã€‚

```bash
python scripts/train.py --gpu 0
```
*å‚æ•°è¯´æ˜ï¼šå¯ä»¥åœ¨ `train.py` ä¸­ä¿®æ”¹ `Config` ç±»æ¥è°ƒæ•´ `batch_size`, `learning_rate` ç­‰å‚æ•°ã€‚*

### 3. å¯¹è¯æµ‹è¯• (Inference)

**ä¸å¾®è°ƒåçš„æ¨¡å‹å¯¹è¯ï¼š**
```bash
python scripts/chat_lora.py --model_path output/qwen-1.5b-lora/best_model
```

**ä¸åŸç”ŸåŸºåº§æ¨¡å‹å¯¹è¯ï¼ˆå¯¹æ¯”ç”¨ï¼‰ï¼š**
```bash
python scripts/chat_base.py
```

### 4. æ¨¡å‹è¯„ä¼° (Evaluation)

**å®šé‡è¯„ä¼°ï¼ˆè®¡ç®— KHP, ROUGE, PPLï¼‰ï¼š**
```bash
python scripts/evaluate.py --model_dir output/qwen-1.5b-lora/best_model --data_file data/test/bjtu_test.json
```

**å®šæ€§å¯¹æ¯”ï¼ˆç”Ÿæˆå¯¹æ¯”æ—¥å¿—ï¼‰ï¼š**
```bash
python scripts/compare_models.py
```

## ğŸ“‚ ç›®å½•ç»“æ„

```text
â”œâ”€â”€ assets/             # æ•ˆæœå›¾è¡¨
â”œâ”€â”€ data/               # è®­ç»ƒä¸æµ‹è¯•æ•°æ®
â”œâ”€â”€ output/             # (è‡ªåŠ¨ç”Ÿæˆ) æ¨¡å‹æƒé‡ä¿å­˜è·¯å¾„
â”œâ”€â”€ scripts/            # æºç 
â”‚   â”œâ”€â”€ train.py        # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ chat_lora.py    # LoRAæ¨¡å‹æ¨ç†
â”‚   â”œâ”€â”€ evaluate.py     # æŒ‡æ ‡è¯„ä¼°
â”‚   â””â”€â”€ ...
â””â”€â”€ logs/               # è¿è¡Œæ—¥å¿—
```

## ğŸ“ å¼•ç”¨ä¸è‡´è°¢

- åŸºç¡€æ¨¡å‹ï¼š[Qwen2.5](https://github.com/QwenLM/Qwen2.5)
- å¾®è°ƒæ¡†æ¶ï¼š[PEFT](https://github.com/huggingface/peft)

## ğŸ“„ License

Apache 2.0